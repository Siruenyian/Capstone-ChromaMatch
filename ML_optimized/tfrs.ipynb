{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy dataset\n",
    "data = {\n",
    "    'Skintone': ['white', 'white', 'dark', 'medium', 'medium'],\n",
    "    'r1': [239, 232, 240, 250, 245],\n",
    "    'g1': [124, 180, 130, 140, 135],\n",
    "    'b1': [142, 184, 150, 160, 155]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "df['Skintone'] = df['Skintone'].astype('category')\n",
    "df['Skintone_code'] = df['Skintone'].cat.codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user embedding\n",
    "user_embedding = Embedding(input_dim=df['Skintone_code'].nunique(), output_dim=embedding_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class RecommenderModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = user_embedding\n",
    "        self.dense_layer = Dense(64, activation='relu')\n",
    "        self.output_layer = Dense(3)  # Number of output features (r1, g1, b1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_embeddings = self.user_embedding(inputs[0])\n",
    "        x = self.dense_layer(user_embeddings)\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        target = features[1]\n",
    "        predicted_output = self(features)\n",
    "        loss = tf.reduce_mean(tf.square(target - predicted_output))\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredError())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({'Skintone_code': df['Skintone_code']}, df[['r1', 'g1', 'b1']]))\n",
    "dataset = dataset.map(lambda x, y: (x, {'target': y})).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\drago\\AppData\\Local\\Temp\\ipykernel_11296\\2949879.py\", line 18, in compute_loss\n        predicted_output = self(features)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\drago\\AppData\\Local\\Temp\\__autograph_generated_filen856zi8f.py\", line 10, in tf__call\n        user_embeddings = ag__.converted_call(ag__.ld(self).user_embedding, (ag__.ld(inputs)[1],), None, fscope)\n\n    AttributeError: Exception encountered when calling layer 'recommender_model_28' (type RecommenderModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\drago\\AppData\\Local\\Temp\\ipykernel_11296\\2949879.py\", line 11, in call  *\n            user_embeddings = self.user_embedding(inputs[1])\n        File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\backend.py\", line 1599, in dtype\n            return x.dtype.base_dtype.name\n    \n        AttributeError: Exception encountered when calling layer 'embedding_21' (type Embedding).\n        \n        'dict' object has no attribute 'dtype'\n        \n        Call arguments received by layer 'embedding_21' (type Embedding):\n          • inputs={'target': 'tf.Tensor(shape=(None, 3), dtype=int64)'}\n    \n    \n    Call arguments received by layer 'recommender_model_28' (type RecommenderModel):\n      • inputs=({'Skintone_code': 'tf.Tensor(shape=(None,), dtype=int8)'}, {'target': 'tf.Tensor(shape=(None, 3), dtype=int64)'})\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[412], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filee9i5p7cc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inputs, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[408], line 18\u001b[0m, in \u001b[0;36mRecommenderModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     17\u001b[0m     target \u001b[39m=\u001b[39m features[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m     predicted_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(features)\n\u001b[0;32m     19\u001b[0m     loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39msquare(target \u001b[39m-\u001b[39m predicted_output))\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filen856zi8f.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m user_embeddings \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39muser_embedding, (ag__\u001b[39m.\u001b[39mld(inputs)[\u001b[39m1\u001b[39m],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdense_layer, (ag__\u001b[39m.\u001b[39mld(user_embeddings),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39moutput_layer, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\drago\\AppData\\Local\\Temp\\ipykernel_11296\\2949879.py\", line 18, in compute_loss\n        predicted_output = self(features)\n    File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\drago\\AppData\\Local\\Temp\\__autograph_generated_filen856zi8f.py\", line 10, in tf__call\n        user_embeddings = ag__.converted_call(ag__.ld(self).user_embedding, (ag__.ld(inputs)[1],), None, fscope)\n\n    AttributeError: Exception encountered when calling layer 'recommender_model_28' (type RecommenderModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\drago\\AppData\\Local\\Temp\\ipykernel_11296\\2949879.py\", line 11, in call  *\n            user_embeddings = self.user_embedding(inputs[1])\n        File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"d:\\Github\\Capstone-ChromaMatch\\.venv\\lib\\site-packages\\keras\\backend.py\", line 1599, in dtype\n            return x.dtype.base_dtype.name\n    \n        AttributeError: Exception encountered when calling layer 'embedding_21' (type Embedding).\n        \n        'dict' object has no attribute 'dtype'\n        \n        Call arguments received by layer 'embedding_21' (type Embedding):\n          • inputs={'target': 'tf.Tensor(shape=(None, 3), dtype=int64)'}\n    \n    \n    Call arguments received by layer 'recommender_model_28' (type RecommenderModel):\n      • inputs=({'Skintone_code': 'tf.Tensor(shape=(None,), dtype=int8)'}, {'target': 'tf.Tensor(shape=(None, 3), dtype=int64)'})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Predict values for a given Skintone\n",
    "skintone_code = 2  # Replace with the desired Skintone code\n",
    "prediction = model({'Skintone_code': tf.constant([skintone_code])}).numpy()\n",
    "print(f\"Predicted values for Skintone {df['Skintone'].cat.categories[skintone_code]}:\")\n",
    "print(prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
